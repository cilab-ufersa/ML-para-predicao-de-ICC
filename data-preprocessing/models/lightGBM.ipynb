{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O LightGBM é um tipo de algoritmo usado para modelos de Aprendizagem de Máquina (AM), que utiliza várias árvores para fazer suas previsões, além de dar um \"boosting\", uma impulsionada para o código.\n",
    "\n",
    "Cada vez que o modelo adiciona uma nova árvore, ela corrige a anterior, tornando seu modelo mais robusto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "![image.png](../figures/light_gbm.png)\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo o Dataset tratado, transformando-o em um DataFrame e armazenando nas variáveis, as colunas referentes as suas características e rótulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_tratado.csv')\n",
    "\n",
    "x = df.drop('ZSN', axis=1)  # Armazenando todas as colunas de características, exceto a última pois ela é a coluna de rótulo\n",
    "y = df['ZSN']               # Armazenado a última coluna, que será o nosso rótulo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando o modelo, usando 20% dos dados para teste e o restante para treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = lgb.Dataset(x_train, label=y_train)\n",
    "test_data = lgb.Dataset(x_test, label=y_test, reference=train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pegando os parâmetros usandos e classificando-os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte que ajusta o comportamento do modelo com base na sua personalização, dessa forma, isso torna o modelo mais eficiente de acordo com o que se espera dele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',      # Define o objetivo da tarefa de aprendizado (regressão ou clasificação)\n",
    "    'metric': 'binary_error',   # Parte que avalia o desempenho do modelo durante o treinamento, calcula a qualidade das previsões de cada iteração\n",
    "    'boosting_type': 'gbdt',    # Define o tipo de boosting a ser usado (gbdt, rf, dart, goss)\n",
    "    'num_leaves': 35,           # Número máximo de folhas em uma árvore\n",
    "    'learning_rate': 0.05,      # Taxa de aprendizado que contrala a contribuição de cada árvore no modelo\n",
    "    'feature_fraction': 0.9     # Fração de featurs a serem consideradas em cada iteração para treinar a árvore\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte dedicada para as métricas do código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 314, number of negative: 1046\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 504\n",
      "[LightGBM] [Info] Number of data points in the train set: 1360, number of used features: 70\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230882 -> initscore=-1.203336\n",
      "[LightGBM] [Info] Start training from score -1.203336\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89       260\n",
      "           1       0.80      0.25      0.38        80\n",
      "\n",
      "    accuracy                           0.81       340\n",
      "   macro avg       0.80      0.62      0.63       340\n",
      "weighted avg       0.81      0.81      0.77       340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_round = 100\n",
    "bst = lgb.train(params, train_data, num_round, valid_sets=[test_data])\n",
    "\n",
    "y_pred = bst.predict(x_test, num_iteration=bst.best_iteration)\n",
    "y_pred_binary = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "\n",
    "print(classification_report(y_test, y_pred_binary, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
