{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Decision Tree**\n",
    "Com as métricas abaixo, podemos observar que os primeiros resultados do modelo foram abaixo do esperado, pois mesmo algumas porcentagens estando acima da média, como acurácia ou precisão, elas não definem se esses resultados foram realmente bons.\n",
    "\n",
    "<center>\n",
    "\n",
    "![image.png](../figures/metricas-1_decision_tree.png)\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Precisão**\n",
    "Na precisão, cerca de 83% das previsões do modelo referente a verdadeiros negativos está correta, ou seja, o modelo quando preve que o paciente não está com insuficiência cardíaca crônica, ele acerta 83% das vezes. \n",
    "\n",
    "Já nas previsões de verdadeiros positivos ele acerta cerca de 46%, significa que quando o modelo preve se o paciente têm insuficiência cardíaca crônica, ele acerta apenas 46% das vezes.\n",
    "\n",
    "#### **Acurácia**\n",
    "Na acurácia, o modelo teve uma taxa de acerto de 75%, De modo geral, é um resultado mediano, pois ele pode indicar que levando em consideração todas as previsões, ele tem 75% de chance de estar certo, mas mesmo assim, não define se o modelo realmente alcançou os objetivos desejados.\n",
    "\n",
    "#### **Sensibilidade e F1-Score**\n",
    "Em relação a sensibilidade e f1-score, os valores estão próximos, indicando que o modelo está com um balanceamento consideravelmente bom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusão**\n",
    "Em relação a precisão, se tratando dos verdadeiros negativos, esses resultados não são nem um pouco relevantes, pois o importante é saber quando que o paciente terá uma insuficiência, e não o contrário, dessa forma, mesmo as taxas de previsões referentes aos verdadeiros negativos sendo altas, elas não são tão significativas. Agora se tratando dos verdadeiros positivos, os resultados estão muito baixos, e esses são os resultados mais importantes, pois eles preveem se o paciente irá ter ou não uma insuficiência cardíaca crónica.\n",
    "\n",
    "Já a sensibilidade está com valores muito baixos para os verdadeiros positivos, ou seja, é o mesmo problema da precisão, tendo apenas 42% de acertos, significando que uma grande porção significativa de casos positivos não está sendo capturado pelo modelo, mais da metade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LightGBM**\n",
    "\n",
    "Nas métricas abaixo, podemos observar que os primeiros resultados do modelo foram acima da média.\n",
    "\n",
    "<center>\n",
    "\n",
    "![image.png](../figures/metricas-1_lightgbm.png)\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Precisão**\n",
    "Na precisão, cerca de 81% das previsões do modelo referente a verdadeiros negativos está correta, ou seja, o modelo quando preve que o paciente não está com insuficiência cardíaca crônica, ele acerta 81% das vezes. \n",
    "\n",
    "Já nas previsões de verdadeiros positivos ele acerta cerca de 80%, significa que quando o modelo preve se o paciente têm insuficiência cardíaca crônica, ele acerta 80% das vezes, um grande aumento em comparação com o modelo decision tree.\n",
    "\n",
    "#### **Acurácia**\n",
    "Na acurácia, o modelo teve uma taxa de acerto de 81%, de modo geral, é um resultado acima da média, pois ele pode indicar que levando em consideração todas as previsões, ele tem 81% de chance de estar certo, mas mesmo assim, não define se o modelo realmente alcançou os objetivos desejados.\n",
    "\n",
    "#### **Sensibilidade e F1-Score**\n",
    "Em relação a sensibilidade e f1-score, os valores estão próximos, indicando que o modelo está com um balanceamento considerável."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusão**\n",
    "Se tratando da precisão, os verdadeiros positivos e os verdadeiros negativos estão com uma taxa acima da média, isso é bom, mas ainda pode melhorar.\n",
    "\n",
    "Já se tratando da sensibilidade, ele se saiu pior que o modelo decision tree, apenas 25% dos verdadeiros positivos estão sendo capturados pelo modelo, isso é péssimo, pois mesmo a sensibilidade referente aos verdadeiros negativos sendo quase de 100%, eles não são o nosso objetivo principal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Random Forest**\n",
    "\n",
    "Nas métricas abaixo, podemos observar que os primeiros resultados do modelo foram acima da média.\n",
    "\n",
    "<center>\n",
    "\n",
    "![image.png](../figures/metricas-1_random_forest.png)\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Precisão**\n",
    "Na precisão, cerca de 81% das previsões do modelo referente a verdadeiros negativos está correta, ou seja, o modelo quando preve que o paciente não está com insuficiência cardíaca crônica, ele acerta 81% das vezes. \n",
    "\n",
    "Já nas previsões de verdadeiros positivos ele acerta cerca de 83%, significa que quando o modelo preve se o paciente têm insuficiência cardíaca crônica, ele acerta 83% das vezes, um grande aumento em comparação com o modelo decision tree, já em comparação com o LightGBM, ela teve apenas um aumento de 3%.\n",
    "\n",
    "#### **Acurácia**\n",
    "Na acurácia, o modelo teve uma taxa de acerto de 81%, de modo geral, é um resultado acima da média, pois ele pode indicar que levando em consideração todas as previsões, ele tem 81% de chance de estar certo, mas mesmo assim, não define se o modelo realmente alcançou os objetivos desejados.\n",
    "\n",
    "#### **Sensibilidade e F1-Score**\n",
    "Em relação a sensibilidade e f1-score, os valores estão próximos, indicando que o modelo está com um balanceamento considerável."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusão**\n",
    "Se tratando da precisão, os verdadeiros positivos e os verdadeiros negativos estão com uma taxa acima da média, isso é bom, mas ainda pode melhorar.\n",
    "\n",
    "Já se tratando da sensibilidade, ele se saiu pior que o modelo decision tree, apenas 25% dos verdadeiros positivos estão sendo capturados pelo modelo, isso é péssimo, pois mesmo a sensibilidade referente aos verdadeiros negativos sendo quase de 100%, eles não são o nosso objetivo principal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conclusão Geral**\n",
    "\n",
    "Dos 3 modelos que foram apresentados acima, os que tiveram um melhor desempenho foram o LightGBM e o Random Forest, sendo o Random Forest, apenas 3% melhor que o LightGBM no requisito precisão.\n",
    "\n",
    "Mas como o nosso foco é uma sensibilidade alta, pois o objetivo é ter o máximo de previsões possíveis, o Decision Tree teve um retorno melhor que o restante.\n",
    "\n",
    "Acreditamos que com a aplicação de algumas técnicas como, Cross Validation e balanceamento, pode-se aumentar as métricas dos nossos modelos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
